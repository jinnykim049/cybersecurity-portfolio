# Step 8: Future Work - Alerting and Dashboard Creation   
**Objectives** 
Extend the project beyond one-time analysis by:
- Setting up real-time alert
- Designing a reusable dashboard for monitoring
-  Planning for future improvements and integration with automated response systems (e.g., SOAR)


* 1) Setting up real-time alert 
This is a Use Case followed by the defined rule:
“If a single IP address triggers more than 20 failed login attempts in 1 hour, trigger an alert.”

**SPL Query for Alert**
index=splunk_project_index sourcetype="_json"
| spath
| search EventID=4625
| rex field=Message "(?s)Account For Which Logon Failed:.*?Account Name:\t(?<AccountName>[^\r\n]+)"
| rex field=Message "Source Network Address:\t(?<SourceIP>\S+)"
| bin _time span=1h
| stats count by SourceIP, _time
| where count > 20

Here is how to Set the Alert in Splunk- 
1. Go to Search & Reporting
2. Run the query above
3. Click Save As -> Alert
4. Set:
Title: Potential Brute-Force Attack (High Risk)
Description: More than 20 failed login attempts from one Source IP  
Permission: Private
Alert type: Scheduled - Run every hour 
Trigger Condition: if results > 0
Trigger: For each result 
Throttle:  Enabled for SourceIP – Suppress triggering for 60 seconds. 
Actions: Email (yejink0610@gmail.com - my personal email)

5. Save the configuration 

(View image: Personal Project/Brute-force login attempt detection and response project (Splunk)/Windows_Event_Logs/Appendix/Screenshots/Screenshot 2025-08-04 at 5.23.24 PM.png)
* Reason for setting Throttle: Used to prevent duplicate notifications if the same IP is detected repeatedly. Useful when there is a lot of data or when an attacker is constantly trying.   


=> I configured a scheduled alert to monitor for IP addresses that trigger more than 20 failed login attempts within a 1-hour window.
This threshold helps detect both aggressive and stealthy brute-force attacks while reducing false positives.
The alert runs hourly and notifies me via email when any matching IP is detected.
To avoid duplicate alerts, I enabled Throttle, which suppresses repeated notifications for 60 seconds. 



* 2) Dashboard Creation 
A security dashboard offers a centralized view of key security metrics to help detect and respond to threats efficiently. It visualizes trends, anomalies, and high-risk activities in real time. This supports rapid incident response and informed decision-making by reducing the need to manually sift through large volumes of raw logs.

Creating my own dashboard was important because it allowed me to define and visualize the exact indicators relevant to brute-force login attempts.  


This is what I did to create my own Dashboard: 
1. I first navigated to Search & Reporting - Dashboards - Create New Dashboard - 
2. Set: 
Dashboard Title - Brute-Force Detection Dashboard 
Description - This dashboard provides visibility into brute-force login attempts by analyzing failed logon events (EventID 4625). It highlights high-risk IPs, attack trends over time, geolocation mapping, and lookup-based threat correlation. 
Permissions - Private 

then clicked on Classic Dashboards 
3. I navigated back to Search & Reporting and ran the queries that I wanted on the dashboard.
After running each query, I clicked "Save As - Existing Dashboard" and selected "Brute-Force Detection Dashboard" - the one that I created in the previous step. Then I named each. 

For example, I named this query as **"Top Brute-Force IPs"**. 
- 
source="sample_windows_event_log.json" index="splunk_project_index" sourcetype="_json"
| spath
| search EventID=4625
| rex field=Message "Source Network Address:\t(?<SourceIP>\S+)"
| stats count by SourceIP
| sort -count

Then I clicked "save to Dashboard" to save the configuration. 

I did rest of the queries in the same way. 


**"Top Brute-Force IPs with Account Context"**
 source="sample_windows_event_log.json" host="Jinnys-MacBook-Pro.local" index="splunk_project_index" sourcetype="_json"
| spath
| search EventID=4625
| rex field=Message "(?s)Account For Which Logon Failed:.*?Account Name:\t(?<AccountName>[^\r\n]+)"
| rex field=Message "Source Network Address:\t(?<SourceIP>\S+)"
| rex field=Message "Logon Type:\t+(?<LogonType>\d+)"
| where LogonType == "3"
| stats count by SourceIP, AccountName
| sort -count

**"Detect Brute-Force attacks with GeoIP enrichment"**
source="sample_windows_event_log.json" host="Jinnys-MacBook-Pro.local" index="splunk_project_index" sourcetype="_json"
| spath
| search EventID=4625
| rex field=Message "(?s)Account For Which Logon Failed:.*?Account Name:\t(?<AccountName>[^\r\n]+)"
| rex field=Message "Source Network Address:\t(?<SourceIP>\S+)"
| rex field=Message "Logon Type:\t+(?<LogonType>\d+)"
| where LogonType == "3"
| iplocation SourceIP
| fillnull value="N/A" City Country Region lat lon
| stats count by SourceIP, AccountName, City, Country, Region, lat, lon
| sort -count 

**"Time-Based Attack Trend"**
source="sample_windows_event_log.json" host="Jinnys-MacBook-Pro.local" index="splunk_project_index" sourcetype="_json"
| spath
| search EventID=4625
| rex field=Message "(?s)Account For Which Logon Failed:.*?Account Name:\t(?<AccountName>[^\r\n]+)"
| rex field=Message "Source Network Address:\t(?<SourceIP>\S+)"
| timechart span=1m count 

=> For this query, viewing a visualized chart is more effective than using the Statistics table. Therefore, I navigated to the Visualization tab and selected Line Chart. When configuring the panel, I set the visualization type to Line Chart accordingly. 

**"Flag High-Risk IPs"**
source="sample_windows_event_log.json" host="Jinnys-MacBook-Pro.local" index="splunk_project_index" sourcetype="_json"
| spath
| search EventID=4625
| rex field=Message "(?s)Account For Which Logon Failed:.*?Account Name:\t(?<AccountName>[^\r\n]+)"
| rex field=Message "Source Network Address:\t(?<SourceIP>\S+)"
| bin _time span=1h 
| stats count by SourceIP, _time
| eval RiskLevel=if(count > 20, "High", "Normal")
| sort -count

 
* Note: 
I excluded Export Suspicious IPs to Lookup Table from Dashboard because the output lookup command is responsible for storing data (record the results as .csv). This is a task that the user will run manually, or automate with a scheduler (for example, alert). The dashboard is a visualization panel, so the file save command doesn't fit.

Similarly, I excluded the lookup-based cross-check mechanism. While it is useful for correlating current activity with known malicious IPs, the lookup returned no matches during the demo period. This panel can be added later when real-time data or a populated lookup table is available. 


3. After adding these panels, I navigated to Search & Reporting - Dashboards tap on the left top. Then I could see this Dashboard below.
(View image: 
Full- Personal Projects/Brute-force login attempt detection and response project (Splunk)/Windows_Event_Logs/Appendix/Screenshots/Screenshot 2025-08-04 at 9.54.26 PM.png

Close-up- Brute-force login attempt detection and response project (Splunk)/Windows_Event_Logs/Appendix/Screenshots/Screenshot 2025-08-04 at 9.55.37 PM.png, Brute-force login attempt detection and response project (Splunk)/Windows_Event_Logs/Appendix/Screenshots/Screenshot 2025-08-04 at 9.56.07 PM.png )


* Role of My Brute-Force Detection Dashboard: 
To sum up, the custom Brute-Force Detection Dashboard I built focuses specifically on identifying and analyzing failed login attempts (EventID 4625) to detect brute-force attacks. It highlights top offending IPs, targeted accounts, geolocation of attack sources, and time-based trends. Each panel is tailored to support investigation and risk assessment, helping simulate real-world SOC workflows. Unlike generic dashboards, this one is purpose-built to address a specific attack vector with actionable insights. 



# Step 9: Future Improvements  
To evolve this project beyond a static monitoring solution, I plan to implement the following enhancements:

1. Integration with SOAR (e.g., Splunk Phantom)
Automating threat response actions through a Security Orchestration, Automation, and Response (SOAR) platform like Splunk Phantom will significantly reduce incident response time and human effort. Possible automated actions include:
- Blocking suspicious IP addresses via firewall APIs
- Creating incident tickets in ticketing systems (e.g., ServiceNow)
- Sending threat intelligence data to external feeds or shared platforms
- Triggering multi-factor authentication (MFA) challenges for targeted accounts
=> This allows a full cycle from detection to response, turning the dashboard into an active defense system.

2. Enhanced Dataset Quality for Realism
Currently, synthetic windows event logs generated by chatGpt-4o provide controlled and predictable behavior. While this is ideal for prototyping and visualization, real-world variability is critical for robust detection. To improve data quality, I can collect logs from honeypots, threat intelligence labs, or abuse feeds (e.g., AbuseIPDB). They should include diverse timestamps, user accounts, geolocations, and behavioral anomalies, while ensuring IP addresses are valid and externally routable to make GeoIP enrichment meaningful. Better quality of sample log data set will better simulate real-world attack scenarios and support more realistic alerting and response logic.

3. MITRE ATT&CK Framework Integration
Mapping observed events to the MITRE ATT&CK framework (https://attack.mitre.org/) helps standardize detection logic and facilitates threat modeling. For example:
3.1 Brute-force login attempts map to T1110 – Brute Force
3.2 Suspicious PowerShell execution (in extended versions) could map to T1059.001 – PowerShell
This integration improves threat visibility and aligns with industry-standard practices for incident response.

* Note: MITRE ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) is a globally recognized framework that outlines how real-world attackers behave.

4. Long-Term Monitoring Enhancements
In future phases, I may also explore:
- Integrating Splunk Machine Learning Toolkit (MLTK) for anomaly detection
- Creating scheduled lookup table updates for continuous threat intelligence matching
- Adding risk scores and correlation searches to prioritize threats 

=> These improvements aim to make the system smarter, more adaptive, and capable of continuous, real-time security monitoring—similar to what real-world SOCs rely on.  